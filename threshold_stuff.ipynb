{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from helpers import * \n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "ufc = pd.read_csv('ufc-master.csv')\n",
    "\n",
    "AD = data_prep_and_feat_engineering(ufc, cat_thresh=0.001, squared_thresh=0.0625)\n",
    "best_approach = ufc.copy() ## creating a new copy of the data to manipulate\n",
    "best_cols = AD['approach 6'][1] ## features from approach 6\n",
    "best_approach, best_cols = performance_index(best_approach, best_cols, diff=True) ## creating performance index difference variable\n",
    "\n",
    "best_approach = best_approach.dropna(subset=best_cols)\n",
    "\n",
    "best_feats = best_approach[best_cols]\n",
    "targ = [0 if victor == 'Red' else 1 for victor in best_approach['Winner']]\n",
    "\n",
    "best_feats_rs, best_targ_rs = resample_dataframe(best_feats, targ)\n",
    "\n",
    "le = LabelEncoder()\n",
    "num, cat = num_and_cat(best_feats_rs)\n",
    "\n",
    "for col in cat:\n",
    "    best_feats_rs[col] = le.fit_transform(best_feats_rs[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[364 101]\n",
      " [ 83 367]]\n",
      "Best F1 Score: 0.8111380145278451\n",
      "Best Threshold: 0.6000000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(best_feats_rs, best_targ_rs, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Test thresholds to find the best one\n",
    "thresholds = np.arange(0, 1.1, 0.1)\n",
    "best_f1_score = 0\n",
    "best_threshold = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresholded = (rf_classifier.predict_proba(X_test)[:,1] > threshold).astype(int)\n",
    "    f1 = f1_score(y_test, y_pred_thresholded)\n",
    "    if f1 > best_f1_score:\n",
    "        best_f1_score = f1\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(\"Best F1 Score:\", best_f1_score)\n",
    "print(\"Best Threshold:\", best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_leaf=1, min_samples_split=2)\n",
    "\n",
    "new_rf.fit(X_train, y_train)\n",
    "\n",
    "new_rf_probs = new_rf.predict_proba(X_test)\n",
    "\n",
    "y_pred_thresholded = (new_rf_probs[:, 1] > best_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8284153005464481"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "accuracy_score(y_pred_thresholded, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013698630136986"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_pred_thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic_ml_stuff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
